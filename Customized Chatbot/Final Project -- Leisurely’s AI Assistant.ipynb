{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from io import BytesIO\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_oai = OpenAI(api_key=openai_api_key)\n",
    "client_ds = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "你是一位面试官，而我准备参加小学数学教师招聘面试，需试讲人教版小学数学某节选片段，试讲分导入、新授、练习巩固、小结、作业五部分（必须有这五个部分且必须按照以下顺序）。接下来我会上传我的试讲内容，请用中文点评我的试讲表现，给出我的缺点，并告诉我如何改正。  \n",
    "1.导入：生动有趣，具教育性，体现学科融合与时政（如：“同学们，喜欢《西游记》吗？最爱谁？孙悟空？对，他会七十二变！看大屏幕，金箍棒时长时短，像新闻里的伸缩科技，怎么量它？今天我们学习毫米、分米！”）。  \n",
    "2.新授：目标明确，重点突出，符合课标与教材，内容准确，结构完整，挖掘智能与思想因素，难易适度，步骤清晰，重难点处理得当，方法灵活，启发性强，主导与主体结合，思维活跃，反馈良好。  \n",
    "3.练习巩固：帮助学生对新授的内容进行巩固练习，承上启下，有趣，面向全体，全班订正。  \n",
    "4.小结：知识性与思想性兼备。  \n",
    "5.注意：融入多样教学法（如小组讨论、小游戏、情境如“买东西找零”），积极鼓励，互动频繁，时长10-15分钟。  \n",
    "最后提供板书设计（突出重点）。\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(history, message):\n",
    "    for x in message[\"files\"]:\n",
    "        # 检查是否是音频文件（假设支持常见格式如 .wav, .mp3）\n",
    "        if x.lower().endswith((\".wav\", \".mp3\", \".m4a\")):\n",
    "            with open(x, \"rb\") as audio_file:\n",
    "                transcription = client_oai.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\", \n",
    "                    file=audio_file\n",
    "                )\n",
    "            history.append({\"role\": \"user\", \"content\": transcription.text})\n",
    "\n",
    "    if message[\"text\"] is not None:\n",
    "        history.append({\"role\": \"user\", \"content\": message[\"text\"]})\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oai_4omini_bot(history: list):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    stream = client_oai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    full_response = ''\n",
    "    for chunk in stream:\n",
    "        full_response += chunk.choices[0].delta.content or ''   \n",
    "        history[-1][\"content\"] = full_response \n",
    "        yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oai_4o_bot(history: list):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    stream = client_oai.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        stream=True)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    full_response = ''\n",
    "    for chunk in stream:\n",
    "        full_response += chunk.choices[0].delta.content or ''   \n",
    "        history[-1][\"content\"] = full_response \n",
    "        yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_v3_bot(history: list):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    stream = client_ds.chat.completions.create(\n",
    "        model='deepseek-chat',\n",
    "        messages=messages,\n",
    "        stream=True)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    full_response = ''\n",
    "    for chunk in stream:\n",
    "        full_response += chunk.choices[0].delta.content or ''   \n",
    "        history[-1][\"content\"] = full_response \n",
    "        yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_r1_bot(history: list):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    stream = client_ds.chat.completions.create(\n",
    "        model='deepseek-reasoner',\n",
    "        messages=messages,\n",
    "        stream=True)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    full_response = ''\n",
    "    for chunk in stream:\n",
    "        full_response += chunk.choices[0].delta.content or ''   \n",
    "        history[-1][\"content\"] = full_response \n",
    "        yield history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot(history, model_choice):\n",
    "    # 根据 model_choice 调用不同的 bot 函数\n",
    "    if model_choice == \"GPT 4o-mini\":\n",
    "        yield from oai_4omini_bot(history)  # 使用 yield from 传递生成器结果\n",
    "    elif model_choice == \"GPT 4o\":\n",
    "        yield from oai_4o_bot(history)\n",
    "    elif model_choice == \"DeepSeek V3\":\n",
    "        yield from ds_v3_bot(history)\n",
    "    elif model_choice == \"DeepSeek R1\":\n",
    "        yield from ds_r1_bot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zekin\\AppData\\Local\\Temp\\ipykernel_78368\\3652135178.py:5: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(elem_id=\"这是陈老师做的\", bubble_full_width=False, type=\"messages\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://7e7cc61ff4d0f610eb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7e7cc61ff4d0f610eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"# Welcom Teacher Xie!👩🏻‍🏫\n",
    "                **让我们一起来练习吧~🤺**\n",
    "    \"\"\")\n",
    "    chatbot = gr.Chatbot(elem_id=\"这是陈老师做的\", bubble_full_width=False, type=\"messages\")\n",
    "\n",
    "    model_choice = gr.Dropdown(\n",
    "                label=\"选择模型\",\n",
    "                choices=[\"GPT 4o-mini\", \"GPT 4o\", \"DeepSeek V3\", \"DeepSeek R1\"],\n",
    "                value=\"GPT 4o-mini\"  # 默认选择 \n",
    "            )\n",
    "\n",
    "    chat_input = gr.MultimodalTextbox(\n",
    "        interactive=True,\n",
    "        file_count=\"multiple\",\n",
    "        placeholder=\"Enter message or upload file...\",\n",
    "        show_label=False,\n",
    "        sources=[\"microphone\", \"upload\"],\n",
    "    )\n",
    "\n",
    "    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
    "    bot_msg = chat_msg.then(bot, [chatbot, model_choice], chatbot, api_name=\"bot_response\")\n",
    "    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
